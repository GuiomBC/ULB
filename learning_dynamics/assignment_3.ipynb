{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 1. N-Armed Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 1.1 All $Q_{ai}$ are initialized to 0\n",
    "## 1.2 The rewards are subject to noise according to a normal distribution with mean $Q^∗_{ai}$ and standard deviation $σ_i$ , ∀i = 1, . . . , N ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "For this exercise you will have to implement the N-Armed bandit problem using each of the following\n",
    "action selection methods:\n",
    "\n",
    "* Random\n",
    "* $\\epsilon$-greedy with parameter $\\epsilon$\n",
    "* Softmax with parameter $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "%matplotlib widget\n",
    "\n",
    "class Action:\n",
    "    def __init__(self, name, qStar=1,qSigma=1,qEst=0):\n",
    "        self.name=name\n",
    "        self.qEst=[qEst]\n",
    "        self.qStar=qStar\n",
    "        self.qSigma=qSigma\n",
    "    def generateReward(self):\n",
    "        return np.random.normal(loc=self.qStar, scale=self.qSigma)\n",
    "    def updateQEst(self, action, reward, alfa=0.01):\n",
    "        # Qvalue estimation of action only gets updated when the executed actions equals the name of this actions \n",
    "        if action == self.name:\n",
    "            self.qEst.append(self.qEst[-1] + alfa*(reward - self.qEst[-1]))\n",
    "        # Otherwise Qvalue estimation stays the same as the previous round\n",
    "        else:\n",
    "            self.qEst.append(self.qEst[-1])\n",
    "    def plotActionQEvolution(self):\n",
    "        plt.plot(self.qEst, label=self.name)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.xlabel(\"Rounds\")\n",
    "        plt.ylabel(\"Qai estimation\")\n",
    "        plt.title(\"Evolution of Qai estimation for actions: \"+self.name)\n",
    "  \n",
    "class Selection:\n",
    "    def __init__(self, name, actionDescriptions, methodDescription, rounds=1e4, alfa=1e-2):\n",
    "        self.name = name\n",
    "        self.actions= {actionName:Action(actionName, **actionDescriptions[actionName]) for actionName in actionDescriptions.keys()}\n",
    "        self.methodDescription= methodDescription\n",
    "        self.rewards=[0]\n",
    "        for i in range(int(rounds)):\n",
    "            self.updateActions(alfa=alfa)\n",
    "    def selectAction(self):\n",
    "        selectionMethod=self.methodDescription['method']\n",
    "        methodArguments={arg:self.methodDescription[arg] for arg in self.methodDescription.keys() if arg != \"method\"}\n",
    "        actions=list(self.actions.values())\n",
    "        return selectionMethod(actions, **methodArguments).name\n",
    "    def updateActions(self, alfa=0.01):\n",
    "        actionName = self.selectAction()\n",
    "        reward = self.actions[actionName].generateReward()\n",
    "        self.rewards.append(reward)\n",
    "        for action in list(self.actions.values()):\n",
    "            action.updateQEst(actionName, reward, alfa=alfa)\n",
    "    def getCumAverageRewards(self):\n",
    "        subtotal = 0\n",
    "        result=list()\n",
    "        for i in range(len(self.rewards)):\n",
    "            subtotal+=self.rewards[i]\n",
    "            result.append(subtotal/(i+1))\n",
    "        return result\n",
    "    def plotCumAverageRewards(self):\n",
    "        plt.plot(self.getCumAverageRewards(), label=self.name)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.xlabel(\"Rounds\")\n",
    "        plt.ylabel(\"Cumulated average of the rewards\")\n",
    "        plt.title(\"Evolution of the Cumulated average of the rewards over time:\"+self.name)\n",
    "    def plotActionQEvolution(self, actionName):\n",
    "        self.actions[actionName].plotActionQEvolution()\n",
    "    def plotActionQEvolutions(self):\n",
    "        for actionName in self.actions:\n",
    "            self.plotActionQEvolution(actionName)\n",
    "        plt.title(self.name)\n",
    "        plt.title(\"Evolution of Qai estimation for different actions: \"+self.name)\n",
    "        \n",
    "class SelectionReplicated:\n",
    "    def __init__(self, name, actionDescriptions, methodDescription, rounds=1e4, alfa=1e-2, replicates=2e1):\n",
    "        self.name = name\n",
    "        self.replicates=list()\n",
    "        for i in tqdm(range(int(replicates))):\n",
    "            self.replicates.append(Selection(name, actionDescriptions, methodDescription, rounds=rounds, alfa=alfa))\n",
    "    def plotCumAverageRewards(self):\n",
    "        cumAverageRewards_averagedOverReplicates=np.sum([selection.getCumAverageRewards() for selection in self.replicates], axis=0)/len(self.replicates)\n",
    "        plt.plot(cumAverageRewards_averagedOverReplicates, label=self.name)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.xlabel(\"Rounds\")\n",
    "        plt.ylabel(\"Cumulated average of the rewards\")\n",
    "        plt.title(\"Evolution of the Cumulated average of the rewards over time:\"+self.name)\n",
    "    def plotActionQEvolution(self, actionName):\n",
    "        qAverageOverReplicates = np.sum([selection.actions[actionName].qEst for selection in self.replicates],axis=0)/len(self.replicates)\n",
    "        plt.plot(qAverageOverReplicates, label=self.name)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.xlabel(\"Rounds\")\n",
    "        plt.ylabel(\"Qai estimation\")\n",
    "        plt.title(\"Evolution of Qai estimation for different actions\" +self.name )\n",
    "    def plotActionQEvolutions(self):\n",
    "        for actionName in self.replicates[0].actions:\n",
    "            self.plotActionQEvolution(actionName)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.xlabel(\"Rounds\")\n",
    "        plt.ylabel(\"Qai estimation\")\n",
    "        plt.title(\"Evolution of Qai estimation for different actions: \" +self.name )\n",
    "    def plotHistogram(self):\n",
    "        actions_n = list()\n",
    "        labels= list()\n",
    "        for actionName in self.replicates[0].actions:\n",
    "            actions_n.append([len(np.unique(rep.actions[actionName].qEst))-1 for rep in self.replicates])\n",
    "            labels.append(actionName)\n",
    "        plt.figure()\n",
    "        plt.hist(actions_n, alpha=1, label=labels, rwidth=1)\n",
    "        plt.xlabel(\"Times arm is selected\")\n",
    "        plt.ylabel(\"Count over different replications\")\n",
    "        plt.title(\"Histogram number of times arm is selected: \"+ self.name)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.savefig(\"hist_\"+self.name+\".png\", format=\"png\", dpi=150)\n",
    "        plt.show()\n",
    "    \n",
    "class SelectionComparison:\n",
    "    def __init__(self, name, actionDescriptions, methodDescriptions, rounds=1e4, alfa=1e-2, replicates=2e1):\n",
    "        self.name=name\n",
    "        self.selectionMethods = {selectionMethod:SelectionReplicated(selectionMethod, \n",
    "                                                                     actionDescriptions, \n",
    "                                                                     methodDescriptions[selectionMethod], \n",
    "                                                                     rounds=rounds, \n",
    "                                                                     alfa=alfa, \n",
    "                                                                     replicates=replicates) \n",
    "                                 for selectionMethod in methodDescriptions.keys()}\n",
    "    def plotCumAverageRewards(self):\n",
    "        plt.figure()\n",
    "        for selectionMethod in self.selectionMethods.values():\n",
    "            selectionMethod.plotCumAverageRewards()\n",
    "        plt.title(\"Comparison of the Cumulated average of the rewards over time.\")\n",
    "        plt.savefig(\"CumAverageReward.png\", format=\"png\", dpi=150)\n",
    "        plt.show()\n",
    "    def plotActionQEvolution(self, actionName):\n",
    "        plt.figure()\n",
    "        qStar = list(self.selectionMethods.values())[0].replicates[0].actions[actionName].qStar\n",
    "        \n",
    "        plt.axhline(y=qStar, label=\"Qai*=\"+str(qStar), color=\"black\", linestyle=\"--\")\n",
    "        for selectionMethod in self.selectionMethods.values():\n",
    "            selectionMethod.plotActionQEvolution(actionName)\n",
    "        plt.title(\"Comparison of Qa estimate over time: \"+ actionName)\n",
    "        plt.savefig(\"actionEvolution_\"+actionName+\".png\", format=\"png\", dpi=150)\n",
    "        plt.show()\n",
    "    def plotActionQEvolutions(self):\n",
    "        actionNames = list(self.selectionMethods.values())[0].replicates[0].actions\n",
    "        for actionName in actionNames:\n",
    "            self.plotActionQEvolution(actionName)\n",
    "    def plotHistogram(self):\n",
    "        for strategy in self.selectionMethods.values():\n",
    "            strategy.plotHistogram()\n",
    "    \n",
    "    \n",
    "def selectRandom(actions):\n",
    "    return np.random.choice(actions)\n",
    "\n",
    "def selectGreedy(actions, e=1):\n",
    "    if np.random.random() < e:\n",
    "        return selectRandom(actions)\n",
    "    else:\n",
    "        return sorted(actions, key= lambda x:x.qEst[-1], reverse=True)[0]\n",
    "    \n",
    "def selectSoftmax(actions, tau=1e6):   \n",
    "    def term(action):\n",
    "        return np.exp(action.qEst[-1]/tau)\n",
    "    terms = np.array([term(action) for action in actions])\n",
    "    cumterms = np.sum(terms)\n",
    "    p_actions = terms/cumterms\n",
    "    return np.random.choice(actions, p=p_actions)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7620e292d6204c6a9176c5fc6c2704a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18624d62a5724ecfad17ecbcae6a3d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6f4a391ff44500a1175e5e014d6af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c35be94bce432e983d30b1a89b56ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc79fc73bb884f55baffd766e750352e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f8c66fa5684d228a140b05bdbcef9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "qEst0=0    \n",
    "actionsDescriptions={\n",
    "    \"Arm 1\":{\"qStar\":2.4, \"qSigma\":0.9, \"qEst\":qEst0},\n",
    "    \"Arm 2\":{\"qStar\":1.3, \"qSigma\":2.0, \"qEst\":qEst0},\n",
    "    \"Arm 3\":{\"qStar\":1.0, \"qSigma\":0.4, \"qEst\":qEst0},\n",
    "    \"Arm 4\":{\"qStar\":2.2, \"qSigma\":0.6, \"qEst\":qEst0}\n",
    "}\n",
    "\n",
    "methodDescriptions={\n",
    "    \"Random\":{\"method\":selectRandom},\n",
    "    \"Greedy e=0.0\":{\"method\":selectGreedy, \"e\":0},\n",
    "    \"Greedy e=0.1\":{\"method\":selectGreedy, \"e\":0.1},\n",
    "    \"Greedy e=0.2\":{\"method\":selectGreedy, \"e\":0.2},\n",
    "    \"SoftMax tau=1.0\":{\"method\":selectSoftmax, \"tau\":1},\n",
    "    \"SoftMax tau=0.1\":{\"method\":selectSoftmax, \"tau\":0.1},\n",
    "}\n",
    "\n",
    "selections = SelectionComparison(\"Comparison\", actionsDescriptions, methodDescriptions, rounds=1e3, alfa=1e-1, replicates=1e2)\n",
    "selections.plotCumAverageRewards()\n",
    "selections.plotActionQEvolutions()\n",
    "selections.plotHistogram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2be374e0c34a91bbaa7302eacb57f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54500c33b5a945779956cf7200d25fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d23306c4f047ae93f7ab270cad5a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75292a128cd4fd683fbaef607e97f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606730c0afd641e0a8b2bb2b7a8f58ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddcac5e576948a4bf497ad4336f9025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "qEst0=0    \n",
    "m = 2 #multiplication\n",
    "actionsDescriptions={\n",
    "    \"Arm 1\":{\"qStar\":2.4, \"qSigma\":0.9*m, \"qEst\":qEst0},\n",
    "    \"Arm 2\":{\"qStar\":1.3, \"qSigma\":2.0*m, \"qEst\":qEst0},\n",
    "    \"Arm 3\":{\"qStar\":1.0, \"qSigma\":0.4*m, \"qEst\":qEst0},\n",
    "    \"Arm 4\":{\"qStar\":2.2, \"qSigma\":0.6*m, \"qEst\":qEst0}\n",
    "}\n",
    "\n",
    "methodDescriptions={\n",
    "    \"Random\":{\"method\":selectRandom},\n",
    "    \"Greedy e=0.0\":{\"method\":selectGreedy, \"e\":0},\n",
    "    \"Greedy e=0.1\":{\"method\":selectGreedy, \"e\":0.1},\n",
    "    \"Greedy e=0.2\":{\"method\":selectGreedy, \"e\":0.2},\n",
    "    \"SoftMax tau=1.0\":{\"method\":selectSoftmax, \"tau\":1},\n",
    "    \"SoftMax tau=0.1\":{\"method\":selectSoftmax, \"tau\":0.1},\n",
    "}\n",
    "\n",
    "selections = SelectionComparison(\"Comparison\", actionsDescriptions, methodDescriptions, rounds=1e3, alfa=1e-1, replicates=1e2)\n",
    "selections.plotCumAverageRewards()\n",
    "selections.plotActionQEvolutions()\n",
    "selections.plotHistogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8247defcf3334d468a05f9174e52b13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d4d08edd6943e482f99fd1fee929d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8340c5ded74136a9fb8111d8db110e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567e6660e8fa40358be5e056f2097a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "def selectGreedyDecreasing(actions, power=1.0/2.0):\n",
    "    t = len(actions[0].qEst)\n",
    "    e = 1/(t**power)\n",
    "    if np.random.random() < e:\n",
    "        return selectRandom(actions)\n",
    "    else:\n",
    "        return sorted(actions, key= lambda x:x.qEst[-1], reverse=True)[0]\n",
    "\n",
    "qEst0=0    \n",
    "m = 1 #multiplication\n",
    "actionsDescriptions={\n",
    "    \"Arm 1\":{\"qStar\":2.4, \"qSigma\":0.9*m, \"qEst\":qEst0},\n",
    "    \"Arm 2\":{\"qStar\":1.3, \"qSigma\":2.0*m, \"qEst\":qEst0},\n",
    "    \"Arm 3\":{\"qStar\":1.0, \"qSigma\":0.4*m, \"qEst\":qEst0},\n",
    "    \"Arm 4\":{\"qStar\":2.2, \"qSigma\":0.6*m, \"qEst\":qEst0}\n",
    "}\n",
    "\n",
    "methodDescriptions={\n",
    "    \"Greedy decreasing\":{\"method\":selectGreedyDecreasing, \"power\":(1.0/2.0)},\n",
    "    \"Greedy e=0.0\":{\"method\":selectGreedy, \"e\":0},\n",
    "    \"Greedy e=0.1\":{\"method\":selectGreedy, \"e\":0.1},\n",
    "    \"Greedy e=0.2\":{\"method\":selectGreedy, \"e\":0.2},\n",
    "}\n",
    "\n",
    "selections = SelectionComparison(\"Comparison\", actionsDescriptions, methodDescriptions, rounds=1e3, alfa=1e-1, replicates=1e2)\n",
    "selections.plotCumAverageRewards()\n",
    "selections.plotActionQEvolutions()\n",
    "selections.plotHistogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1b3f47cfa64f6a9d046a38df04b39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15fd3da8ebd452ba8ee2bec84210f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e26895b4d04b74a8ece18886131efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "def selectSoftmaxDecreasing(actions, maxT=1e3, maxTau=4.0, minTau=1e-2):\n",
    "    def term(action):\n",
    "        t = len(actions[0].qEst)\n",
    "        tau = minTau+ maxTau*(maxT -t)/(maxT)\n",
    "        return np.exp(action.qEst[-1]/tau)\n",
    "    terms = np.array([term(action) for action in actions])\n",
    "    cumterms = np.sum(terms)\n",
    "    p_actions = terms/cumterms\n",
    "    return np.random.choice(actions, p=p_actions)    \n",
    "\n",
    "rounds=1e3\n",
    "qEst0=0    \n",
    "m = 1 #multiplication\n",
    "actionsDescriptions={\n",
    "    \"Arm 1\":{\"qStar\":2.4, \"qSigma\":0.9*m, \"qEst\":qEst0},\n",
    "    \"Arm 2\":{\"qStar\":1.3, \"qSigma\":2.0*m, \"qEst\":qEst0},\n",
    "    \"Arm 3\":{\"qStar\":1.0, \"qSigma\":0.4*m, \"qEst\":qEst0},\n",
    "    \"Arm 4\":{\"qStar\":2.2, \"qSigma\":0.6*m, \"qEst\":qEst0}\n",
    "}\n",
    "\n",
    "methodDescriptions={\n",
    "    \"SoftMax Decreasing\":{\"method\":selectSoftmaxDecreasing, \"maxT\":rounds, \"maxTau\":4.0},\n",
    "    \"SoftMax tau=1.0\":{\"method\":selectSoftmax, \"tau\":1},\n",
    "    \"SoftMax tau=0.1\":{\"method\":selectSoftmax, \"tau\":0.1},\n",
    "}\n",
    "\n",
    "selections = SelectionComparison(\"Comparison\", actionsDescriptions, methodDescriptions, rounds=rounds, alfa=1e-1, replicates=1e2)\n",
    "selections.plotCumAverageRewards()\n",
    "selections.plotActionQEvolutions()\n",
    "selections.plotHistogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 2. Stochastic Reward Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "%matplotlib widget\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, gameRewards, rounds=5e3, initialValue=0):\n",
    "        self.gameRewards=gameRewards\n",
    "        self.agents=self.generateAgents(initialValue=[initialValue])\n",
    "        self.rewards=[0]\n",
    "        for i in range(int(rounds)):\n",
    "            self.main()\n",
    "    def getReward(self, actionA, actionB):\n",
    "        jointAction = tuple(sorted([actionA, actionB]))\n",
    "        state=self.gameRewards[jointAction]\n",
    "        rewardFunction=state[\"rewardFunction\"]\n",
    "        params = {key: value for key, value in state.items() if key != \"rewardFunction\"} \n",
    "        return rewardFunction(**params)\n",
    "    def generateAgents(self, initialValue=[0,]):\n",
    "        nAgents = len(list(self.gameRewards)[0])\n",
    "        Agents = list()\n",
    "        for i in range(nAgents):\n",
    "            rewardBelieves = {key:initialValue[:] for key in self.gameRewards.keys()} \n",
    "            actions = sorted(np.unique([key[i] for key in self.gameRewards.keys()]))\n",
    "            game= self\n",
    "            Agents.append(Agent(actions, rewardBelieves, game))\n",
    "        for agent in Agents:\n",
    "            agent.generateInitialActionBelieves(list(set(Agents)-{agent}))\n",
    "        return Agents\n",
    "    def updateActionBelieves(self, agentActions):\n",
    "        for agent in self.agents:\n",
    "            agent.updateActionBelieves(agentActions)\n",
    "    def updateRewardBelieves(self, agentActions, reward):\n",
    "        for agent in self.agents:\n",
    "            agent.updateRewardBelieves(agentActions, reward)\n",
    "    def getCumAverageRewards(self):\n",
    "        subtotal = 0\n",
    "        result=list()\n",
    "        for i in range(len(self.rewards)):\n",
    "            subtotal+=self.rewards[i]\n",
    "            result.append(subtotal/(i+1))\n",
    "        return result\n",
    "    def main(self):\n",
    "        agentActions = {agent:agent.chooseAction() for agent in self.agents}\n",
    "        self.updateActionBelieves(agentActions)\n",
    "        jointAction = tuple(sorted(agentActions.values()))\n",
    "        self.rewards.append(self.getReward(*jointAction))\n",
    "        reward = self.rewards[-1]\n",
    "        self.updateRewardBelieves(agentActions, reward)\n",
    "        \n",
    "    \n",
    "class Agent:\n",
    "    def __init__(self, actions, initialBelievesReward, game):\n",
    "        self.actions=actions\n",
    "        self.rewardBelieves=initialBelievesReward\n",
    "        self.game=game\n",
    "    def generateInitialActionBelieves(self, otherAgents):\n",
    "        self.actionBelieves=dict()\n",
    "        for agent in otherAgents:\n",
    "            self.actionBelieves[agent]=list((np.random.choice(agent.actions, size=int(2e1))))\n",
    "    def updateActionBelieves(self, agentActions):\n",
    "        for agent in list(agentActions):\n",
    "            if agent != self:\n",
    "                self.actionBelieves[agent]=[agentActions[agent]]+self.actionBelieves[agent][:-1]\n",
    "    def updateRewardBelieves(self, agentActions, reward, alfa=0.1):\n",
    "        jointAction=tuple(sorted(agentActions.values()))\n",
    "        for key in list(self.rewardBelieves):\n",
    "            lastBelieve=self.rewardBelieves[key][-1]\n",
    "            if jointAction == key:\n",
    "                #reward=game.getReward(*jointAction)\n",
    "                newBelieve= lastBelieve + alfa*(reward - lastBelieve)\n",
    "                self.rewardBelieves[key].append(newBelieve)\n",
    "            else:\n",
    "                self.rewardBelieves[key].append(lastBelieve)\n",
    "    def otherAgents(self):\n",
    "        return list(set(game.agents)-{self})\n",
    "    def actionBelieves2prob(self):\n",
    "        # Bad code, does only work because there are just two agents\n",
    "        for agent in self.actionBelieves.keys():\n",
    "            actionss = self.actionBelieves[agent] + agent.actions\n",
    "            actions, counts = np.unique(actionss, return_counts=True)\n",
    "            probs = (counts-1) / float(len(self.actionBelieves[agent]))\n",
    "            return list(zip(actions, probs))\n",
    "    def predictRewards(self):\n",
    "        actionProbs = self.actionBelieves2prob()\n",
    "        probs = np.array([value[1] for value in actionProbs])\n",
    "        r=list()\n",
    "        actions = list()\n",
    "        for action in self.actions:\n",
    "            combinations = sorted([key for key in self.rewardBelieves.keys() if action in key])\n",
    "            rewards = np.array([self.rewardBelieves[comb][-1] for comb in combinations])\n",
    "            r.append(np.average(rewards*probs))\n",
    "            actions.append(action)\n",
    "        return r,actions\n",
    "    def strategyBoltzmann(self, tau=1):\n",
    "        def term(reward):\n",
    "            return np.exp(reward/tau)\n",
    "        rewards, actions = self.predictRewards()\n",
    "        terms = np.array([ term(reward) for reward in rewards])\n",
    "        cumterms = np.sum(terms)\n",
    "        p_actions = terms/cumterms\n",
    "        return p_actions\n",
    "    def chooseAction(self):\n",
    "        return np.random.choice(self.actions, p=self.strategyBoltzmann())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95d1b5e3f164d1eba9bb3c0db54da92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62dff6e221da4888bbdd82ecf97e171b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca006d8715ad460c82bf5b272492e57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "rounds=50\n",
    "\n",
    "sigma0= 0.2\n",
    "sigma1= 0.2\n",
    "sigma= 0.2\n",
    "gameRewards = {\n",
    "    ('a1','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma0, \"loc\":11},\n",
    "    ('a1','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":-30},\n",
    "    ('a1','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a2','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":-30},\n",
    "    ('a2','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma1, \"loc\":7},\n",
    "    ('a2','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":6},\n",
    "    ('a3','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a3','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a3','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":5},\n",
    "}\n",
    "\n",
    "Rewards=list()\n",
    "OptimisticRewards=list()\n",
    "\n",
    "for i in range(rounds):\n",
    "    game = Game(gameRewards, initialValue=0)\n",
    "    Rewards.append(game.getCumAverageRewards())\n",
    "    gameOptimistic = Game(gameRewards, initialValue=50)\n",
    "    OptimisticRewards.append(gameOptimistic.getCumAverageRewards())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.average(Rewards,axis=0), label = \"Boltzmann (tau=1)\")\n",
    "plt.plot(np.average(OptimisticRewards,axis=0), label = \"Optimistic Boltzmann (tau=1)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average collected reward per episode\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"sigma0=\"+str(sigma0)+\" sigma1=\"+str(sigma1)+\" sigma=\"+str(sigma))\n",
    "plt.savefig(\"ex2/1.png\", format=\"png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "sigma0= 4\n",
    "sigma1= 0.1\n",
    "sigma= 0.1\n",
    "gameRewards = {\n",
    "    ('a1','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma0, \"loc\":11},\n",
    "    ('a1','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":-30},\n",
    "    ('a1','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a2','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":-30},\n",
    "    ('a2','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma1, \"loc\":7},\n",
    "    ('a2','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":6},\n",
    "    ('a3','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a3','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a3','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":5},\n",
    "}\n",
    "\n",
    "Rewards=list()\n",
    "OptimisticRewards=list()\n",
    "\n",
    "for i in range(rounds):\n",
    "    game = Game(gameRewards, initialValue=0)\n",
    "    Rewards.append(game.getCumAverageRewards())\n",
    "    gameOptimistic = Game(gameRewards, initialValue=50)\n",
    "    OptimisticRewards.append(gameOptimistic.getCumAverageRewards())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.average(Rewards,axis=0), label = \"Boltzmann (tau=1)\")\n",
    "plt.plot(np.average(OptimisticRewards,axis=0), label = \"Optimistic Boltzmann (tau=1)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average collected reward per episode\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"sigma0=\"+str(sigma0)+\" sigma1=\"+str(sigma1)+\" sigma=\"+str(sigma))\n",
    "plt.savefig(\"ex2/2.png\", format=\"png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "sigma0= 0.1\n",
    "sigma1= 4\n",
    "sigma= 0.1\n",
    "gameRewards = {\n",
    "    ('a1','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma0, \"loc\":11},\n",
    "    ('a1','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":-30},\n",
    "    ('a1','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a2','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":-30},\n",
    "    ('a2','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma1, \"loc\":7},\n",
    "    ('a2','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":6},\n",
    "    ('a3','b1'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a3','b2'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":0},\n",
    "    ('a3','b3'):{\"rewardFunction\":np.random.normal, \"scale\":sigma, \"loc\":5},\n",
    "}\n",
    "\n",
    "Rewards=list()\n",
    "OptimisticRewards=list()\n",
    "\n",
    "for i in range(rounds):\n",
    "    game = Game(gameRewards, initialValue=0)\n",
    "    Rewards.append(game.getCumAverageRewards())\n",
    "    gameOptimistic = Game(gameRewards, initialValue=50)\n",
    "    OptimisticRewards.append(gameOptimistic.getCumAverageRewards())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.average(Rewards,axis=0), label = \"Boltzmann (tau=1)\")\n",
    "plt.plot(np.average(OptimisticRewards,axis=0), label = \"Optimistic Boltzmann (tau=1)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Average collected reward per episode\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"sigma0=\"+str(sigma0)+\" sigma1=\"+str(sigma1)+\" sigma=\"+str(sigma))\n",
    "plt.savefig(\"ex2/3.png\", format=\"png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
