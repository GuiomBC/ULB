{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>SFML-Project-Classification-INFO-F422</h1> </center>\n",
    "\n",
    "<center> <h2>Bernard Manderick</h2> </center>\n",
    " \n",
    "<center> <h3>Guillaume Buisson-Chavot</h3> </center> \n",
    "<center> <h3>matricule: 000465822 </h3> </center> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question: We want to know if there is a difference between 2 machine learning algorithms in terms of errors.\n",
    "\n",
    "For that, we will create a synthetic set in order to test the 2 algorithms on it before to apply them on a real-world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "X, y =  make_blobs(n_samples=1000, centers=2, n_features=2, cluster_std= (2,2), center_box = (-10,10))\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print a small part of the values of the dataframe we create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x         y  label\n",
      "0  10.207311 -5.180247      0\n",
      "1   7.872766 -3.913635      1\n",
      "2   9.835486 -5.800608      0\n",
      "3   7.312659 -2.842581      1\n",
      "4  11.954994 -4.710721      0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Support vector machine with packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Support vector machine method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence = 0.8466666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X = np.array(df.drop(['label'], 1))\n",
    "y = np.array(df['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf_svm = SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(X_train, y_train)\n",
    "confidence_svm = clf_svm.score(X_test, y_test)\n",
    "print('confidence =', confidence_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Support vector machine from scratch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also developed this algorithm from scratch with explainations. Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is a supervised machine learning algorithm used in general for binary classification problems. Given a set of training examples, each marked as belonging to one or the other of two categories, a SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier. An SVM model is a representation of the examples as points in space, mapped such that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code of the cost function:\n",
    "$$J(w) = \\frac{1}{2}||w||^2 + C\\left[\\frac{1}{N}\\sum\\limits_{i}^{n}max(0, 1-y_i * (w \\cdotp x_i + b))\\right]$$\n",
    "The first part of the function corresponds to the margin, in fact the width between the two (positive and negative) hyperplanes is equal to: \n",
    "$$width = (x_+ - x_-)* \\frac{w}{||w||}$$ and joining the previous equation with the following equations of the two hyperplanes:\n",
    "$$y_i*(w x_+ + b) -1 = 0$$ and $$ y_i*(w x_- + b) -1 = 0$$ with $$y_i = \\begin{cases}\n",
    "  1 & \\text{for } x_+  \\\\   \n",
    "  -1 & \\text{for } x_-\n",
    "\\end{cases}$$\n",
    "we obtain $$width = \\frac{2}{||w||}$$ and we have to maximize the width which is the same to minimize w and the trick is to transform  $$\\text{min }w$$ into $$ min\\frac{1}{2}||w||^2$$ \n",
    "The second part of the function which begins by C is called Hinge loss function and we have to minimize the sum which corresponds to distance between positive (or negative) hyperplane and our training set. C is a regularization parameter, larger C results in narrow margin and a smaller in a wider margin. N is just the number of lines we have in ours features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_function(W, X, Y):\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0    # the max between 0 and the distance is kept\n",
    "    hinge_loss = C * (np.sum(distances) / X.shape[0])\n",
    "    return 1 / 2 * np.dot(W, W) + hinge_loss ## = cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code of the gradient of the cost function:\n",
    "\n",
    "We can simplify $$max(0, 1-y_i * (w \\cdotp x_i + b))$$ into $$max(0, 1-y_i * (W \\cdotp X_i))$$ with $$W =(w,b)$$ and $$X = (x_i,1)$$\n",
    "and we obtain with the previous simplification:\n",
    "\n",
    "$$J(w) = \\frac{1}{2}||w||^2 + C\\left[\\frac{1}{N}\\sum\\limits_{i}^{n}max(0, 1-y_i * (W \\cdotp X_i))\\right]$$\n",
    "and finally, we have the following gradient of the cost function:\n",
    "\n",
    "$$\\nabla_w J(w) = \\frac{1}{N}\\sum\\limits_{i}^{n}\n",
    "\\begin{cases}\n",
    "  w & \\text{if } max(0, 1-y_i * (W \\cdotp X_i))=0 \\\\   \n",
    "  w-Cy_ix_i    & \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_function_gradient(W, X, Y):\n",
    "    Y = np.array([Y])\n",
    "    X = np.array([X]) \n",
    "    distances = 1 - (Y * np.dot(X, W))\n",
    "    grad = np.zeros(len(W))\n",
    "    for index, value in enumerate(distances):\n",
    "        if max(0, value) == 0:\n",
    "            dist = W\n",
    "        else:\n",
    "            dist = W - (C * Y[index] * X[index])\n",
    "        grad += dist\n",
    "    return grad/len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to compute the stochastic gradient descent function: For this purpose, we have to minimise the two parts of the following equation:\n",
    "ð½(ð‘¤)=12||ð‘¤||2+ð¶[1ð‘âˆ‘ð‘–ð‘›ð‘šð‘Žð‘¥(0,1âˆ’ð‘¦ð‘–âˆ—(ð‘Šâ‹…ð‘‹ð‘–))]\n",
    "The gradient is the direction of the inscrease of the function J(w). We need to go to the direction of the decrease, that's why we calculate the gradient of the cost function from the train set. Particularly, we perform the gradient descent by substracting a learning rate multiplied by the gradient of the cost function from the weight initialized with zero value. And we compute the cost for all the 2^n. In this way, we can determine the weight by repeating the procedure a number of times we decide (here 2048 cycles). We can add a criterion to stop before the max_cycles value by comparing the difference between the previous cost and the new cost and if this mesurement is smaller than a percentage of the old cost, we stop the cycles and return directly the weigts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stochastic_gradient_descent(features, outputs):\n",
    "    max_cycles, rate = 2049, 0.001 \n",
    "    weights = np.zeros(features.shape[1])\n",
    "    parameter, cycle = 0, 0\n",
    "    previous_cost = float(\"inf\")\n",
    "    while cycle <max_cycles:\n",
    "        cycle += 1\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        for index, value_of_X in enumerate(X):\n",
    "            ascention = compute_cost_function_gradient(weights, value_of_X , Y[index])\n",
    "            weights = weights - (learning_rate * ascention)\n",
    "        if cycle == 2**parameter:\n",
    "            cost = compute_cost_function(weights, features, outputs)\n",
    "            print(\"nb_of_cycles: {} and Cost: {}\".format(cycle, cost))\n",
    "            parameter +=1\n",
    "            print('cost=', cost)   \n",
    "            if abs(previous_cost - cost) < rate * previous_cost:\n",
    "                cycle = max_cycles\n",
    "            previous_cost = cost\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x         y  label\n",
      "0    10.207311 -5.180247      0\n",
      "1     7.872766 -3.913635      1\n",
      "2     9.835486 -5.800608      0\n",
      "3     7.312659 -2.842581      1\n",
      "4    11.954994 -4.710721      0\n",
      "..         ...       ...    ...\n",
      "995  10.063153 -5.533033      0\n",
      "996  11.111413 -7.238088      0\n",
      "997   7.748518  0.526372      1\n",
      "998  10.289940 -1.894886      1\n",
      "999  12.985773 -9.086449      0\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "C = 10000\n",
    "learning_rate = 0.000001\n",
    "#read and display dataset\n",
    "data = df\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x         y  label\n",
      "0    10.207311 -5.180247    1.0\n",
      "1     7.872766 -3.913635   -1.0\n",
      "2     9.835486 -5.800608    1.0\n",
      "3     7.312659 -2.842581   -1.0\n",
      "4    11.954994 -4.710721    1.0\n",
      "..         ...       ...    ...\n",
      "995  10.063153 -5.533033    1.0\n",
      "996  11.111413 -7.238088    1.0\n",
      "997   7.748518  0.526372   -1.0\n",
      "998  10.289940 -1.894886   -1.0\n",
      "999  12.985773 -9.086449    1.0\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#convert existing labels into 1 et -1 labels\n",
    "diag_map = {0: 1.0, 1: -1.0}\n",
    "data['label'] = data['label'].map(diag_map)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign labels and features to different data frames\n",
    "Y = data.loc[:, 'label']\n",
    "X = data.iloc[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize values of features to avoid overflow\n",
    "X_normalized = MinMaxScaler().fit_transform(X.values)\n",
    "X = pd.DataFrame(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert a new column b full of 1 at the end\n",
    "X.insert(loc=len(X.columns), column='b', value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset to obtain train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "nb_of_cycles: 1 and Cost: 8723.728431019123\n",
      "cost= 8723.728431019123\n",
      "nb_of_cycles: 2 and Cost: 7459.55593901088\n",
      "cost= 7459.55593901088\n",
      "nb_of_cycles: 4 and Cost: 5604.096482409939\n",
      "cost= 5604.096482409939\n",
      "nb_of_cycles: 8 and Cost: 4343.082540293514\n",
      "cost= 4343.082540293514\n",
      "nb_of_cycles: 16 and Cost: 3770.6508345609013\n",
      "cost= 3770.6508345609013\n",
      "nb_of_cycles: 32 and Cost: 3464.0422453761958\n",
      "cost= 3464.0422453761958\n",
      "nb_of_cycles: 64 and Cost: 3338.4405309635704\n",
      "cost= 3338.4405309635704\n",
      "nb_of_cycles: 128 and Cost: 3274.869388756811\n",
      "cost= 3274.869388756811\n",
      "nb_of_cycles: 256 and Cost: 3273.0467956830353\n",
      "cost= 3273.0467956830353\n",
      "training end\n",
      "weights are: [  3.31377033 -11.99079869   4.88936322]\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "print(\"training start\")\n",
    "W = compute_stochastic_gradient_descent(X_train.to_numpy(), y_train.to_numpy())\n",
    "print(\"training end\")\n",
    "print(\"weights are: {}\".format(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply the model on test set:\n",
      "accuracy of svm on test dataset: 0.85\n",
      "precision of svm on test dataset: 0.8478260869565217\n"
     ]
    }
   ],
   "source": [
    "print(\"apply the model on test set:\")\n",
    "y_train_predicted = np.array([])\n",
    "for i in range(X_train.shape[0]):\n",
    "    ypred = np.sign(np.dot(X_train.to_numpy()[i], W))\n",
    "    y_train_predicted = np.append(y_train_predicted, ypred)\n",
    "\n",
    "y_test_predicted = np.array([])\n",
    "for i in range(X_test.shape[0]):\n",
    "    ypred = np.sign(np.dot(X_test.to_numpy()[i], W))\n",
    "    y_test_predicted = np.append(y_test_predicted, ypred)\n",
    "\n",
    "print(\"accuracy of svm on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"precision of svm on test dataset: {}\".format(precision_score(y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Nearest neighbors algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the nearest neighbors algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence = 0.795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)\n",
    "from sklearn.pipeline import Pipeline\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "confidence_knn = nca_pipe.score(X_test, y_test)\n",
    "print('confidence =',confidence_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence = 0.79\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "confidence_knn = nca_pipe.score(X_test, y_test)\n",
    "print('confidence =',confidence_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence = 0.815\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "confidence_knn = nca_pipe.score(X_test, y_test)\n",
    "print('confidence =',confidence_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that if we change k (= n_neighbors = number of neighbors), we can improve the result.\n",
    "\n",
    "Explanations of the KNN algorithm:\n",
    "\n",
    "Given a query point x0, we find the k training points x(r) with r = 1, ..., k closest in distance to x0 and then classify using majority vote among the k neighbors. We use euclidean distance in feature space: d(i) = ||x(i) - xo||\n",
    "We first standardize each of the features to have mean zero and variance 1, since it's possible that they are measured in different units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: We can see that for our synthetic set, SVM algorithm is better than KNN algorithm and if we code the SVM algorithm from scratch, the scores are approximatively the same for SVM with packages.\n",
    "We have to note that these results depends on the set, if the points are more clearly separeted, if the clusters are more distant in space then the results will change and sometimes it's KNN which is more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Real-world dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0   1   2   3   4   5   6   7   8   9   10\n",
      "0  1000025   5   1   1   1   2   1   3   1   1   2\n",
      "1  1002945   5   4   4   5   7  10   3   2   1   2\n",
      "2  1015425   3   1   1   1   2   2   3   1   1   2\n",
      "3  1016277   6   8   8   1   3   4   3   7   1   2\n",
      "4  1017023   4   1   1   3   2   1   3   1   1   2\n",
      "         0   1   2   3   4   5  6   7   8   9   10\n",
      "694  776715   3   1   1   1   3  2   1   1   1   2\n",
      "695  841769   2   1   1   1   2  1   1   1   1   2\n",
      "696  888820   5  10  10   3   7  3   8  10   2   4\n",
      "697  897471   4   8   6   4   3  4  10   6   1   4\n",
      "698  897471   4   8   8   5   4  5  10   4   1   4\n"
     ]
    }
   ],
   "source": [
    "real_data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)\n",
    "print(real_data.head())\n",
    "print(real_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can see there is no hearders, just ascending numbers assigned for each column. We can change that but we have to search the real hearders:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the link corresponding to the features of our data:\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "\n",
    "And we can read from this link that:\n",
    "\n",
    "- the number of Instances: 699 (as of 15 July 1992)\n",
    "\n",
    "- the number of Attributes: 10 plus the class attribute\n",
    "\n",
    "- the following Attribute Information: (class attribute has been moved to last column)\n",
    "\n",
    "Attribute    :           Domain\n",
    "1. Sample code number            : id number\n",
    "2. Clump Thickness               : 1 - 10\n",
    "3. Uniformity of Cell Size       : 1 - 10\n",
    "4. Uniformity of Cell Shape      : 1 - 10\n",
    "5. Marginal Adhesion             : 1 - 10\n",
    "6. Single Epithelial Cell Size   : 1 - 10\n",
    "7. Bare Nuclei                   : 1 - 10\n",
    "8. Bland Chromatin               : 1 - 10\n",
    "9. Normal Nucleoli               : 1 - 10\n",
    "10. Mitoses                      : 1 - 10\n",
    "11. Class                      : (2 for benign, 4 for malignant)\n",
    "\n",
    "\n",
    "- there are 16 missing attribute values\n",
    "\n",
    "There are 16 instances in Groups 1 to 6 that contain a single missing \n",
    "(i.e., unavailable) attribute value, now denoted by \"?\".  \n",
    "\n",
    "- the class distribution:\n",
    " \n",
    "   Benign: 458 (65.5%)\n",
    "   Malignant: 241 (34.5%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we change the headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  Cl_Th  Unif_cell_si  Unif_cell_sh  Mar_adh  S_epith_cell_si B_Nu  \\\n",
      "0  1000025      5             1             1        1                2    1   \n",
      "1  1002945      5             4             4        5                7   10   \n",
      "2  1015425      3             1             1        1                2    2   \n",
      "3  1016277      6             8             8        1                3    4   \n",
      "4  1017023      4             1             1        3                2    1   \n",
      "\n",
      "   B_Chr  Norm_N  Mi  Class  \n",
      "0      3       1   1      2  \n",
      "1      3       2   1      2  \n",
      "2      3       1   1      2  \n",
      "3      3       7   1      2  \n",
      "4      3       1   1      2  \n"
     ]
    }
   ],
   "source": [
    "real_data.columns =['Id', 'Cl_Th','Unif_cell_si', 'Unif_cell_sh', 'Mar_adh', 'S_epith_cell_si', 'B_Nu', 'B_Chr','Norm_N', 'Mi','Class']\n",
    "print(real_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to clean the data, we have 16 missing values denoted by \"?\" according to the file of characteristics, either we remove each line which contains a missing value or we can compute the average or median for each column/feature and attribuate this value for the corresponding missing value or if there are a lot of missing values for a feature, we can remove the feature or finally, we can convert missing values to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the '?' values into nan values in order to use isnull() just after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in ['Id', 'Cl_Th','Unif_cell_si', 'Unif_cell_sh', 'Mar_adh', 'S_epith_cell_si', 'B_Nu', 'B_Chr','Norm_N', 'Mi','Class']:\n",
    "    real_data[val] = real_data[val].replace(['?'],np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "Cl_Th               0\n",
       "Unif_cell_si        0\n",
       "Unif_cell_sh        0\n",
       "Mar_adh             0\n",
       "S_epith_cell_si     0\n",
       "B_Nu               16\n",
       "B_Chr               0\n",
       "Norm_N              0\n",
       "Mi                  0\n",
       "Class               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data[:].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the missing values belong to the 'Bare Nuclei' column. We can thus remove the rows with nan values or drop the 'Bare Nuclei' column but it's more accurate when we keep as much data as possible so the best solution is just to remove the 16 lines that contains nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_without_nan_rows = real_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on real-world dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply different algorithms on our dataset, we first remove the Id column for both which is without interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9658536585365853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guiom/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "real_data_without_nan_rows.drop(['Id'], 1, inplace=True)\n",
    "X = np.array(real_data_without_nan_rows.drop(['Class'], 1))\n",
    "y = np.array(real_data_without_nan_rows['Class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "confidence = clf.score(X_test, y_test)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on real-world dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence = 0.9707317073170731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)\n",
    "from sklearn.pipeline import Pipeline\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "confidence_knn = nca_pipe.score(X_test, y_test)\n",
    "print('confidence =',confidence_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence = 0.9804878048780488\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "confidence_knn = nca_pipe.score(X_test, y_test)\n",
    "print('confidence =',confidence_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence = 0.9804878048780488\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_train, y_train)\n",
    "confidence_knn = nca_pipe.score(X_test, y_test)\n",
    "print('confidence =',confidence_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: we can see that KNN algorithm is more accurate than SVM algorithms if we choose k = 3 for KNN algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
